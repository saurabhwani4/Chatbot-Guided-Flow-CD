{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a21224b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\swani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial import distance\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "import time\n",
    "import webbrowser \n",
    "\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "from multiprocessing import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8bca2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\swani\\Python Projects\\Case Bucket\\Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dcaa4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Length: 107161\n",
      "   Unnamed: 0      Name  Article Number                          N-Grams\n",
      "0           0  20467935          538672            vhdl get csgmss error\n",
      "1           1  20467935          538672            get csgmss error data\n",
      "2           2  20467935          538672           csgmss error data type\n",
      "3           3  20467935          538672       error data type unresolved\n",
      "4           4  20467935          538672  data type unresolved std_ulogic\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('N-Grams Data.xlsx')\n",
    "length = int(len(data))\n",
    "print('Data Length: %d' %(length))\n",
    "print(data.head(5))\n",
    "\n",
    "df = pd.read_excel('ALl-keywords-2021.xlsx')\n",
    "exceptions = df[\"Keywords Flagged by IT\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e9d9bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23868/3934698387.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^\\w\\s]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "a = input()\n",
    "a = a.lower()\n",
    "a = a.replace('[^\\w\\s]','')\n",
    "stop_words = stopwords.words('english')\n",
    "a = [word for word in a.split() if word not in (stop_words)]\n",
    "a = ' '.join(a)\n",
    "a = [word for word in a.split() if word not in (exceptions)]\n",
    "a = ' '.join(a)\n",
    "lmtzr = WordNetLemmatizer()\n",
    "lemmatized = [lmtzr.lemmatize(word) for word in word_tokenize(a)]\n",
    "a = ' '.join(lemmatized)\n",
    "print('')\n",
    "print('Processed input: %s' %(a))\n",
    "\n",
    "ngrams = data['N-Grams']\n",
    "ngrams_list = ngrams.tolist()\n",
    "ngrams_list.append(a)\n",
    "\n",
    "vectorizer = TfidfVectorizer().fit_transform(ngrams_list)\n",
    "input_vector = vectorizer[-1]\n",
    "vectorizer = vectorizer[:-1]\n",
    "\n",
    "cosine_similarities = linear_kernel(vectorizer[:], input_vector).flatten()\n",
    "\n",
    "sort_cs = np.sort(cosine_similarities)[::-1]\n",
    "top3_values = sort_cs[:3]\n",
    "if (any(i >= 0.8 for i in top3_values) is True):\n",
    "    print(top3_values)\n",
    "else:\n",
    "    top3_values = [0,0,0]\n",
    "print('')\n",
    "print(\"Cosine Similarities: \",top3_values)\n",
    "\n",
    "indices_list = []\n",
    "\n",
    "if (all(i == 0 for i in top3_values) is True):\n",
    "    indices_list = [0,0,0]\n",
    "else:\n",
    "    for value in top3_values:\n",
    "        max_list = [i for i,val in enumerate(cosine_similarities) if val==value]\n",
    "        indices_list.append(max_list[0])\n",
    "\n",
    "print('')\n",
    "print(\"Indices of 3 maximum value: \",indices_list)\n",
    "\n",
    "if (indices_list == [0,0,0]):\n",
    "    print('')\n",
    "    print('The KB Articles: None')\n",
    "    KB_Articles = []\n",
    "else:\n",
    "    lst = [data.iloc[i]['Name'] for i in indices_list]\n",
    "    KB_Articles = np.unique(lst)\n",
    "    print('')\n",
    "    print('The KB Articles: %a'%KB_Articles)\n",
    "    unique_indices = [lst.index(i) for i in KB_Articles]\n",
    "\n",
    "print('')\n",
    "print('Output (Similar N-Grams): ')\n",
    "op_ngrams = []\n",
    "if (indices_list == [0,0,0]):\n",
    "    print(\"No N-grams match the input query\")\n",
    "else:\n",
    "    for i in unique_indices:\n",
    "        index = indices_list[i]\n",
    "        op_ngrams.append(ngrams_list[index])\n",
    "    print(op_ngrams)\n",
    "\n",
    "end = time.time()\n",
    "print('')\n",
    "print('Time Taken to Respond: %d seconds' %(end-start))\n",
    "\n",
    "for article in KB_Articles:\n",
    "    str = 'http://cdsinfo.cadence.com/cgi-bin/cdsinfoprod?input={}&type=_&codmode=p'.format(article)\n",
    "    webbrowser.open_new(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f20f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sparse = sparse.csr_matrix(vectorizer)\n",
    "\n",
    "similarities = cosine_similarity(A_sparse)\n",
    "print('pairwise dense output:\\n {}\\n'.format(similarities))\n",
    "\n",
    "#also can output sparse matrices\n",
    "similarities_sparse = cosine_similarity(A_sparse,dense_output=False)\n",
    "print('pairwise sparse output:\\n {}\\n'.format(similarities_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc4e4b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23868/2023253909.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mA_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "A_sparse = sparse.csr_matrix(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b708a996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
